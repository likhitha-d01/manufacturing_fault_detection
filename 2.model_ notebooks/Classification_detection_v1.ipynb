{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classification_detection_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AJ5iCdZVKsaN",
        "RYv62k-uGQUV",
        "JDYvlKbxKxWq",
        "wqneUq65LCM0",
        "d1P0NR7LLT6y",
        "a7VSrlLk2VdJ",
        "mVSR032UdCvf",
        "lbxmdITkL2TX",
        "_ymgD7vLrA-E",
        "LSoM7XTQL5yS",
        "xskYOOLoL7ol",
        "gjgkntmwdupb",
        "EkZwCBP48ncU",
        "g566NyGo1_re",
        "nGZyKHQDL9V5",
        "BAjlCFJs9IHO",
        "DpueROgeMAmA",
        "wCcoJNXKMDAZ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZytusM1GPCJ"
      },
      "source": [
        "# Classification and detection model - Version 1\n",
        "\n",
        "The classification backbone of the model is VGG-16 network along with the detection activation layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvpGmGJE3Nj_"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ5iCdZVKsaN"
      },
      "source": [
        "## CASTING DATA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYv62k-uGQUV"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2E_4VPv4afX"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.GlobalMaxPooling2D()(x_map)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    if out_type == \"classify\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=y)\n",
        "    if out_type == \"map\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDbFkajCHDgG"
      },
      "source": [
        "model = build_model(\"Adam\", 1e-3, \"classify\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYvlKbxKxWq"
      },
      "source": [
        "### Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZIlPBW4KwpV"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NAO88PU8--1"
      },
      "source": [
        "filename = 'casting_dataset.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpDXSDujh2Ql"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'casting_dataset_balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpd2cxHmU0VY"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            brightness_range = [0.8,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=1.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivTMPvTVdpJo"
      },
      "source": [
        "print(len(os.listdir(os.path.join(dataset, 'train', 'def_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'train', 'ok_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'test', 'def_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'test', 'ok_front'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mkka89-hLb7"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqneUq65LCM0"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okBDv1VnLDmm"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0l1fuKUn4Ld"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'casting_V4(50eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxAVY77vFM4-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1P0NR7LLT6y"
      },
      "source": [
        "\n",
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ma34YeHq91"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'casting_V2.h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gro2RJZouEs6"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6kFM1rTpkBB"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dV7_zvvzm3v"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "50 eps\n",
        "\n",
        "loss : 0.11778640002012253\n",
        "accuracy : 0.9632152318954468\n",
        "auc : 0.9908440709114075\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "100 eps\n",
        "\n",
        "loss : 0.04719378054141998\n",
        "accuracy : 0.9863760471343994\n",
        "auc : 0.9984898567199707\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VSrlLk2VdJ"
      },
      "source": [
        "#### Visualise test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DELw_VzGLWW3"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = (preds > 0.75).astype(np.int)\n",
        "\n",
        "        if predicted_value == 0:\n",
        "\n",
        "            confidence = (1- preds) * 100\n",
        "        else:\n",
        "            confidence = preds * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVSR032UdCvf"
      },
      "source": [
        "#### Get Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfVxtpRzdHtJ"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlFTBWR0DHJ"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-3]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image, verbose=1)[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = (preds > 0.6).astype(np.int)\n",
        "\n",
        "        if predicted_value == 0:\n",
        "\n",
        "            confidence = (1- preds) * 100\n",
        "        else:\n",
        "            confidence = preds * 100\n",
        "\n",
        "       \n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wZ1-hck-VE"
      },
      "source": [
        "#### Visualise detection results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1dzdsomJD9"
      },
      "source": [
        "batch_size = 1\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            dtype='float64',\n",
        "                        )\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') \n",
        "disp_images = []\n",
        "\n",
        "pos_idx = 0\n",
        "neg_idx = 0\n",
        "\n",
        "for image, actual in test_generator:\n",
        "\n",
        "    output = actual\n",
        "\n",
        "    if output == 0 and pos_idx < 3:\n",
        "        pos_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    \n",
        "    if output == 1 and neg_idx <3:\n",
        "        neg_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    if neg_idx>=3 and pos_idx>=3:\n",
        "        break\n",
        "\n",
        "disp_images = np.array(disp_images)\n",
        "print(disp_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-Ly_pMmBAx"
      },
      "source": [
        "import matplotlib as mplot \n",
        "\n",
        "def plot_maps(images, maps, k, dims):\n",
        "    map_size=dims[0]\n",
        "    r_size = dims[1]\n",
        "    r_stride = dims[2]\n",
        "    colors = ['#ff0000', '#ff0080', '#ff00ff', '#8000ff', '#0080ff', '#00ffff', '#00ff80']\n",
        "              \n",
        "    fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
        "    for j , (img, mask) in enumerate(zip(images, maps)):\n",
        "        mask = mask.flatten()\n",
        "        j_a = (j-j%3)//3\n",
        "        j_b = j%3\n",
        "        img = np.asarray(img[:,:,0],dtype=np.float32)\n",
        "        ax[j_a][j_b].imshow(img,cmap=plt.get_cmap('gray'))\n",
        "        \n",
        "        for i in range(k):\n",
        "            a_max = np.argmax(mask)\n",
        "            x_region = a_max%map_size#note, numpy addresses work on arr[y, x, z], compared to image coordinates\n",
        "            y_region = (a_max-(a_max%map_size))//map_size\n",
        "            prob = mask[a_max]\n",
        "       \n",
        "            if prob>0.5:break\n",
        "            x_pixel = r_stride*(x_region)\n",
        "            y_pixel = r_stride*(y_region)\n",
        "       \n",
        "            #rectangle expects bottom left coordinates. We've generated Top Right\n",
        "            rectangle = mplot.patches.Rectangle((x_pixel, y_pixel), r_size, r_size, edgecolor=colors[i-1],facecolor=\"none\")\n",
        "            ax[j_a][j_b].add_patch(rectangle)\n",
        "            \n",
        "            font = {'color':colors[i-1]}\n",
        "            ax[j_a][j_b].text(x_pixel,y_pixel,s=\"{0:.3f}\".format(prob), fontdict=font)\n",
        "            \n",
        "            mask[a_max]= 0#to help get the next most maximum\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc-ruMqwlDfH"
      },
      "source": [
        "map_model = keras.models.Model(inputs=[model.input], \n",
        "                               outputs=[model.layers[-2].output])\n",
        "\n",
        "final_layer = model.layers[-1]\n",
        "\n",
        "pred_maps = map_model.predict(disp_images)\n",
        "\n",
        "plot_maps(disp_images, pred_maps, 5,  (15, 32, 14 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbxmdITkL2TX"
      },
      "source": [
        "## SOLAR PANEL DATA \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ymgD7vLrA-E"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITSyZfqqrF3x"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh8gvjlsrA-E"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type, categories):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.Flatten()(x_map)\n",
        "    y_out = keras.layers.Dense(categories, activation='softmax')(y)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    if out_type == \"classify\":casting_V2\n",
        "        model = keras.models.Model(inputs=input_img, outputs=y_out)\n",
        "    if out_type == \"map\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kb5eWjurA-E"
      },
      "source": [
        "map_model = build_model(\"Adam\", 1e-3, \"map\", 2)\n",
        "model = build_model(\"Adam\", 1e-3, \"classify\", 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSoM7XTQL5yS"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIHmBY-nL5Kb"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtcvlhoacpY7"
      },
      "source": [
        "filename = 'solar_panels_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihWOG3lSdHTA"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'solar_panels_products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjUfrM9dOGv"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.5,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.75,\n",
        "                            dtype='float64',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnWkTdw8dR1v"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xskYOOLoL7ol"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQGcviwL8pP"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j7ujMhXdZLC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ux2OtQtdZN1"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'solar_v1(50eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgkntmwdupb"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vX7bxxu1e8N"
      },
      "source": [
        "import keras\n",
        "import os\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "model = keras.models.load_model(os.path.join(model_dir, 'solar_v1(50eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdCpMoV4wwLP"
      },
      "source": [
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=1,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTYizERedt3-"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6X2E74dz26"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "50 epochs\n",
        "\n",
        "loss : 0.38369879126548767\n",
        "accuracy : 0.9211195707321167\n",
        "auc : 0.9531559944152832\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkZwCBP48ncU"
      },
      "source": [
        "#### Visualise test data results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sc-OlBKdz54"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 20:\n",
        "        break\n",
        "\n",
        "    for i in range(1):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g566NyGo1_re"
      },
      "source": [
        "#### Get Activation Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q7ojLfB2CMv"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FR_-FDE2Ipe"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGZyKHQDL9V5"
      },
      "source": [
        "## STEEL DEFECT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjlCFJs9IHO"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTfRkwT9IHY"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "escF-AtQ9IHZ"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type, categories):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.GlobalAveragePooling2D()(x_map)\n",
        "    y_out = keras.layers.Dense(categories, activation='softmax')(y)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpueROgeMAmA"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gef8BJL_73"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "main_dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAdNOTKXfkLI"
      },
      "source": [
        "filename = 'steel_defect_cls_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RzgMKg98iME"
      },
      "source": [
        "dataset = os.path.join(main_dataset_dir, 'steel_defect_cls_products')\n",
        "\n",
        "new_dataset = os.path.join(main_dataset_dir, 'steel_defect_cls_products_cropped')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OhYBVgBBXbm"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset_dir = dataset\n",
        "\n",
        "destination_dir = new_dataset\n",
        "\n",
        "if not os.path.exists(destination_dir):\n",
        "\tos.mkdir(destination_dir)\n",
        "\n",
        "for data_split in os.listdir(dataset_dir):\n",
        "\n",
        "\tprint('\\n', data_split, '\\n')\n",
        "\n",
        "\tdatasplit_path = os.path.join(dataset_dir, data_split)\n",
        "\n",
        "\tdestination_split = os.path.join(destination_dir, data_split)\n",
        "\n",
        "\tif not os.path.exists(destination_split):\n",
        "\t\tos.mkdir(destination_split)\n",
        "\n",
        "\tfor category in os.listdir(datasplit_path):\n",
        "\n",
        "\t\tprint('\\n', category, '\\n')\n",
        "\n",
        "\t\tcategory_path = os.path.join(datasplit_path, category)\n",
        "\n",
        "\t\tdestination_category = os.path.join(destination_split, category)\n",
        "\n",
        "\t\tif not os.path.exists(destination_category):\n",
        "\t\t\tos.mkdir(destination_category)\n",
        "\n",
        "\t\tfor image_name in tqdm(os.listdir(category_path)):\n",
        "\n",
        "\t\t\timage_path = os.path.join(category_path, image_name)\n",
        "\n",
        "\t\t\timage = cv2.imread(image_path)\n",
        "\n",
        "\t\t\theight, width, _ = image.shape\n",
        "\n",
        "\t\t\tnew_width = int(width /6) \n",
        "\n",
        "\t\t\tfor idx in range(6):\n",
        "\n",
        "\t\t\t\tnew_image = image[:, idx* new_width: (idx + 1) * new_width, : ]\n",
        "\n",
        "\t\t\t\tunique_values = len(np.unique(new_image))\n",
        "\n",
        "\t\t\t\tdestination_image_path = os.path.join(destination_category, image_name.split('.')[0] + '_' + str(idx) + '.jpg')\n",
        "\n",
        "\n",
        "\t\t\t\tif unique_values > 120 and not os.path.exists(destination_image_path):\n",
        "\n",
        "\t\t\t\t\tcv2.imwrite(destination_image_path, new_image)\n",
        "\n",
        "\t\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zTKW4PTfkOH"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.75,1.0],\n",
        "                            zoom_range=0.0,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZZvuIsLfkQ7"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(new_dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training') \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(new_dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation') \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqQsCcb4Dgh0"
      },
      "source": [
        "a = next(train_generator)\n",
        "for img in a[0]:\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmjzmPvC9QFq"
      },
      "source": [
        "number_of_classes = len(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTXLmvvfkTS"
      },
      "source": [
        "map_model = build_model(\"SGD\", 1e-3, \"map\", number_of_classes)\n",
        "model = build_model(\"SGD\", 1e-3, \"classify\", number_of_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcoJNXKMDAZ"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP8Y1J7QMD8W"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-8, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr],\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jkckAwvhE2h"
      },
      "source": [
        " import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roP26cLXhIpX"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'steel_V3(50eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK0goCVbf2d2"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5O-r-VNYDr"
      },
      "source": [
        "for folder in os.listdir(os.path.join(new_dataset, 'train')):\n",
        "    print(folder)\n",
        "    print(len(os.listdir(os.path.join(new_dataset, 'train', folder))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsJl4tALFBv"
      },
      "source": [
        "test_generator = generator.flow_from_directory( os.path.join(new_dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWUqOnJzf4je"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCxzvJVf4m1"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "epochs 50 - V1\n",
        "\n",
        "loss : 0.8872455358505249\n",
        "accuracy : 0.7154929637908936\n",
        "auc : 0.8439496159553528\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "epochs 50 - V2\n",
        "\n",
        "loss : 1.2701878547668457\n",
        "accuracy : 0.34939759969711304\n",
        "auc : 0.6427261233329773\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "v3 - epochs 50\n",
        "\n",
        "loss : 0.9832906723022461\n",
        "accuracy : 0.5500945448875427\n",
        "auc : 0.8196025490760803\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkpoi34xf4q6"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlAJVNXfCpxj"
      },
      "source": [
        "#### Visualise Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmV3mfrCsjx"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51FJkm-Cxp3"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}