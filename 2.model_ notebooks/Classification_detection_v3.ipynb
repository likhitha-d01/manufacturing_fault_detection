{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_detection_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TTSl2V67BjLa",
        "8nxbvTEuyCA_",
        "9rLLlgFTzCxZ",
        "RmKerJ8Z0dbT",
        "VT13r2CgethF",
        "gHw5oJV2Pwkx",
        "onpyzN-xP2fp",
        "trFIrlejKrLJ",
        "A08-8dXpJ-pA",
        "AJ5iCdZVKsaN",
        "5A2O2tSAzRfJ",
        "BnJrbpkLzRfi",
        "ija1EeDtzRfm",
        "OUBjsOSBzRfo",
        "PRwaKKND_w_Y",
        "TyMuJMYp4_Qt",
        "9hWUphbGE4cl",
        "PjcK-9UiE4co",
        "nGZyKHQDL9V5",
        "BAjlCFJs9IHO",
        "DpueROgeMAmA",
        "YYkxJNzzK4JH",
        "wCcoJNXKMDAZ",
        "iK0goCVbf2d2",
        "T_LQyJgTfMnb",
        "wlAJVNXfCpxj",
        "LffvkuKjyAGG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpliXsx4BiL-"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv8gf0OfoR7x"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTSl2V67BjLa"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooaD_FCStWjx"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJ6tbLR9fuj"
      },
      "source": [
        "def build_model(optimizer, learning_rate, number_of_categories):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    \n",
        "    y_out = keras.layers.Flatten()(mapping_layer)\n",
        "    y_out = keras.layers.Dense(number_of_categories, activation='softmax')(y_out)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nxbvTEuyCA_"
      },
      "source": [
        "## METAL SURFACE DATA\n",
        "\n",
        "The dataset was downloaded from [here](https://www.kaggle.com/fantacher/neu-metal-surface-defects-data).\n",
        "\n",
        "Extract the zip folder and rename the inside folder to `'metal_surface_dataset'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rLLlgFTzCxZ"
      },
      "source": [
        "### Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSxbIHdBzJEi"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_sUDzrHzJNn"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'metal_surface_products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H_gzK4LzaWM"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.9,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=1.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float32',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPxgXtgzdWN"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hhkqH9gz6wO"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "print(attribute_to_idx)\n",
        "\n",
        "number_of_attributes = len(attribute_to_idx)\n",
        "print(number_of_attributes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc42ud_dzCT6"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-4, number_of_attributes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmKerJ8Z0dbT"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IJM5Om1H0c1b"
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, min_lr = 1e-9, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I7Bobhy1NyB"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'metal_surface_V1.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLohE-F1pPF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print(\"accuracy\")\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "print(\"auc\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"lr\")\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACdjiPk_1usN"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97WHogB1xAa"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'metal_surface_V1.h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5laMAq111ui"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG6OGToC11xr"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY4K9njj16Vi"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "20 eps\n",
        "\n",
        "loss : 0.04393177479505539\n",
        "accuracy : 1.0\n",
        "auc : 1.0\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsNzrTAaeTan"
      },
      "source": [
        "#### Visualise test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXkO8l4TeTa4"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds,axis=0)\n",
        "\n",
        "        confidence = preds[predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT13r2CgethF"
      },
      "source": [
        "#### Get Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRonpJP1ethH"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = keras.layers.Flatten()(classifier_input)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        #last_conv_layer_output = tf.reshape(last_conv_layer_output,[1,-1])\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-tqd8vvethK"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-3]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image, verbose=1)[0]\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=0)\n",
        "\n",
        "        confidence = preds[predicted_value] * 100\n",
        "       \n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHw5oJV2Pwkx"
      },
      "source": [
        "## CIVIL SURFACE CRACK DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onpyzN-xP2fp"
      },
      "source": [
        "### Pre-processing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7seyOUlnP6fT"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import matplotlib as mplot\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o09P_7hkWrC8"
      },
      "source": [
        "filename = 'civil_surface_defect_dataset.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk0npbfdQjX2"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'civil_surface_defect_dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBx8SualQjaK"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=5,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.8,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=255.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-KdOUgWQjdD"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGL0gcJ0KP_5"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "number_of_attributes = len(attribute_to_idx)\n",
        "attribute_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADqEt8otJj0q"
      },
      "source": [
        "a = next(train_generator)\n",
        "\n",
        "for img in a[0][:5]:\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trFIrlejKrLJ"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-T-hUDnKs04"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPYyKxicKs33"
      },
      "source": [
        "def build_model(optimizer, learning_rate):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    mapping_layer = keras.layers.Activation(\"sigmoid\")(mapping_layer)\n",
        "\n",
        "    y_out = keras.layers.GlobalMaxPooling2D()(mapping_layer)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79f-u4b3KI-Q"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-4)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A08-8dXpJ-pA"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OkVVCuKAah"
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br1LQ7ciMwxG"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'civil_surface_V2(20eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKG6HcL_MNYp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print(\"accuracy\")\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "print(\"auc\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"lr\")\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOcethPbM6Ze"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiR6HTO7M8DP"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'civil_surface_V2(20eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24MpIGL7NE7m"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUQGVrrbHumY"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Dz7F96NO3s"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "V2 - 20 eps\n",
        "loss : 0.2489970624446869\n",
        "accuracy : 0.9800000190734863\n",
        "auc : 0.9999999403953552\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmG-PI1xNfiU"
      },
      "source": [
        "#### Visualize test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxetrKKzNO6L"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = (preds > 0.75).astype(np.int)\n",
        "\n",
        "        if predicted_value == 0:\n",
        "\n",
        "            confidence = (1- preds) * 100\n",
        "        else:\n",
        "            confidence = preds * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WRaLCD5Pe7j"
      },
      "source": [
        "#### Visualise detection results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1BAq8UnPmql"
      },
      "source": [
        "batch_size = 1\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical') \n",
        "disp_images = []\n",
        "\n",
        "pos_idx = 0\n",
        "neg_idx = 0\n",
        "\n",
        "for image, actual in test_generator:\n",
        "\n",
        "    output = np.argmax(actual, axis=1)[0]\n",
        "\n",
        "    if output == 0 and pos_idx < 3:\n",
        "        pos_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    \n",
        "    if output == 1 and neg_idx <3:\n",
        "        neg_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    if neg_idx>=3 and pos_idx>=3:\n",
        "        break\n",
        "\n",
        "disp_images = np.array(disp_images)\n",
        "print(disp_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKlVuZbfPpzL"
      },
      "source": [
        "import matplotlib as mplot\n",
        "\n",
        "def plot_maps(images, maps, k, dims):\n",
        "    map_size=dims[0]\n",
        "    r_size = dims[1]\n",
        "    r_stride = dims[2]\n",
        "    colors = ['#ff0000', '#ff0080', '#ff00ff', '#8000ff', '#0080ff', '#00ffff', '#00ff80']\n",
        "              \n",
        "    fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
        "    for j , (img, mask) in enumerate(zip(images, maps)):\n",
        "        mask = mask.flatten()\n",
        "        j_a = (j-j%3)//3\n",
        "        j_b = j%3\n",
        "        img = np.asarray(img[:,:,0],dtype=np.float32)/255\n",
        "        ax[j_a][j_b].imshow(img,cmap=plt.get_cmap('gray'))\n",
        "        \n",
        "        for i in range(k):\n",
        "            a_max = np.argmax(mask)\n",
        "            x_region = a_max%map_size#note, numpy addresses work on arr[y, x, z], compared to image coordinates\n",
        "            y_region = (a_max-(a_max%map_size))//map_size\n",
        "            prob = mask[a_max]\n",
        "       \n",
        "            if prob<0.5:break\n",
        "            x_pixel = r_stride*(x_region)\n",
        "            y_pixel = r_stride*(y_region)\n",
        "       \n",
        "            #rectangle expects bottom left coordinates. We've generated Top Right\n",
        "            rectangle = mplot.patches.Rectangle((x_pixel, y_pixel), r_size, r_size, edgecolor=colors[i-1],facecolor=\"none\")\n",
        "            ax[j_a][j_b].add_patch(rectangle)\n",
        "            \n",
        "            font = {'color':colors[i-1]}\n",
        "            ax[j_a][j_b].text(x_pixel,y_pixel,s=\"{0:.3f}\".format(prob), fontdict=font)\n",
        "            \n",
        "            mask[a_max]= 0#to help get the next most maximum\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nOrqNvvPtwR"
      },
      "source": [
        "map_model = keras.models.Model(inputs=[model.input], \n",
        "                               outputs=[model.layers[-2].output])\n",
        "\n",
        "final_layer = model.layers[-1]\n",
        "\n",
        "pred_maps = map_model.predict(disp_images)\n",
        "\n",
        "plot_maps(disp_images, pred_maps, 5,  (11, 32, 21 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ5iCdZVKsaN"
      },
      "source": [
        "## CASTING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYvlKbxKxWq"
      },
      "source": [
        "### Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZIlPBW4KwpV"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import keras\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZZmnFglcYN0"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'casting_dataset_balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4UcR3ZS0Ywl"
      },
      "source": [
        "for category in os.listdir(dataset + '/train'):\n",
        "    print(category, \":\", len(os.listdir(os.path.join(dataset + '/train', category))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocSXFo-acZGo"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.2,\n",
        "                            dtype='float32',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7yF7UehcZJ4"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9mCWia8c7X5"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO9a_Mzab2Jv"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8HB677Sb2J-"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VpK-7Q7b2J-"
      },
      "source": [
        "def build_model(optimizer, learning_rate):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    mapping_layer = keras.layers.Activation(\"sigmoid\")(mapping_layer)\n",
        "\n",
        "    y_out = keras.layers.GlobalMaxPooling2D()(mapping_layer)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvc2S2z4b2J-"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-3)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqneUq65LCM0"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFEhzgDDbCzh"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ics6fTYmdLBB"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'casting_V2( eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yF6vwfdMhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1P0NR7LLT6y"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DELw_VzGLWW3"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'casting_V2(100 eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFZtTz4RiDAO"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLPVcsLKKSj9"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWmQloFriDFA"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "V1 - 50 eps\n",
        "\n",
        "loss : 0.2496185153722763\n",
        "accuracy : 0.9482288956642151\n",
        "auc : 0.9841052293777466\n",
        "\n",
        "V2 - 100 eps\n",
        "loss : 0.07995594292879105\n",
        "accuracy : 0.972752034664154\n",
        "auc : 0.9960728287696838\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFXM1B9Hjqri"
      },
      "source": [
        "#### Visualise the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOUAgnQMiDHx"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = 1.0 if preds>0.6 else 0.0\n",
        "\n",
        "        if predicted_value == 1.0:\n",
        "            confidence = preds * 100\n",
        "        else:\n",
        "            confidence = (1 - preds) * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wZ1-hck-VE"
      },
      "source": [
        "#### Visualise detection results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1dzdsomJD9"
      },
      "source": [
        "batch_size = 1\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            dtype='float64',\n",
        "                        )\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') \n",
        "disp_images = []\n",
        "\n",
        "pos_idx = 0\n",
        "neg_idx = 0\n",
        "\n",
        "for image, actual in test_generator:\n",
        "\n",
        "    output = int(actual[0])\n",
        "\n",
        "    if output == 0 and pos_idx < 3:\n",
        "        pos_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    \n",
        "    if output == 1 and neg_idx <3:\n",
        "        neg_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    if neg_idx>=3 and pos_idx>=3:\n",
        "        break\n",
        "\n",
        "disp_images = np.array(disp_images)\n",
        "print(disp_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-Ly_pMmBAx"
      },
      "source": [
        "def plot_maps(images, maps, k, dims):\n",
        "    map_size=dims[0]\n",
        "    r_size = dims[1]\n",
        "    r_stride = dims[2]\n",
        "    colors = ['#ff0000', '#ff0080', '#ff00ff', '#8000ff', '#0080ff', '#00ffff', '#00aa80', '#bb0080',  '#cc0080', '#dd0080',]\n",
        "              \n",
        "    fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
        "    for j , (img, mask) in enumerate(zip(images, maps)):\n",
        "        mask = mask.flatten()\n",
        "        j_a = (j-j%3)//3\n",
        "        j_b = j%3\n",
        "        img = np.asarray(img[:,:,0],dtype=np.float32)\n",
        "        ax[j_a][j_b].imshow(img,cmap=plt.get_cmap('gray'))\n",
        "        \n",
        "        for i in range(k):\n",
        "            a_max = np.argmax(mask)\n",
        "            x_region = a_max%map_size#note, numpy addresses work on arr[y, x, z], compared to image coordinates\n",
        "            y_region = (a_max-(a_max%map_size))//map_size\n",
        "            prob = mask[a_max]\n",
        "       \n",
        "            if prob>0.7:break\n",
        "            x_pixel = r_stride*(x_region)\n",
        "            y_pixel = r_stride*(y_region)\n",
        "       \n",
        "            #rectangle expects bottom left coordinates. We've generated Top Right\n",
        "            rectangle = mplot.patches.Rectangle((x_pixel, y_pixel), r_size, r_size, edgecolor=colors[i-1],facecolor=\"none\")\n",
        "            ax[j_a][j_b].add_patch(rectangle)\n",
        "            \n",
        "            font = {'color':colors[i-1]}\n",
        "            ax[j_a][j_b].text(x_pixel,y_pixel,s=\"{0:.3f}\".format(1 - prob), fontdict=font)\n",
        "            \n",
        "            mask[a_max]= 0#to help get the next most maximum\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc-ruMqwlDfH"
      },
      "source": [
        "map_model = keras.models.Model(inputs=[model.input], \n",
        "                               outputs=[model.layers[-2].output])\n",
        "\n",
        "final_layer = model.layers[-1]\n",
        "\n",
        "pred_maps = map_model.predict(disp_images)\n",
        "\n",
        "plot_maps(disp_images, pred_maps, 10,  (15, 32, 14))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A2O2tSAzRfJ"
      },
      "source": [
        "## SOLAR PANEL DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnJrbpkLzRfi"
      },
      "source": [
        "### Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YVFVXVhzRfj"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import keras\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHOUZw92-VX"
      },
      "source": [
        "filename = 'solar_panels_products_v3.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFrD1ACjzRfj"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'solar_panels_products_v3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15JW1_MbzRfk"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.9,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float32',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtaq9x82zRfl"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcQB2jTAzRfl"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ija1EeDtzRfm"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFVVAjHQzRfm"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDXSOwufzRfn"
      },
      "source": [
        "def build_model(optimizer, learning_rate):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    mapping_layer = keras.layers.Activation(\"sigmoid\")(mapping_layer)\n",
        "\n",
        "    y_out = keras.layers.GlobalMaxPooling2D()(mapping_layer)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvUwxVG3zRfn"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-4)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDP3q0kjJ8wm"
      },
      "source": [
        "for category in os.listdir(dataset+ '/train'):\n",
        "\n",
        "    print(category, \":\", len(os.listdir(dataset+'/train/'+category)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUBjsOSBzRfo"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJXXPKURzRfo"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs=  epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8oQEHoGzRfo"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'solar_V1(50 eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llaZxXcZzRfo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IILHtqdVzRfp"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB6NDXKlzRfp"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'solar_V1(50 eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUC_96LszRfp"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ORhvmuNu8v"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdTndY4zRfq"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "20 eps\n",
        "\n",
        "loss : 0.20308108627796173\n",
        "accuracy : 0.9868420958518982\n",
        "auc : 1.0\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoBBLmWdzRfq"
      },
      "source": [
        "#### Visualise the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_KEdmGhzRfq"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = 1.0 if preds>0.6 else 0.0\n",
        "\n",
        "        if predicted_value == 1.0:\n",
        "            confidence = preds * 100\n",
        "        else:\n",
        "            confidence = (1 - preds) * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BhfOeiOzRft"
      },
      "source": [
        "#### Visualise detection results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um0gisquzRfu"
      },
      "source": [
        "batch_size = 1\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            dtype='float64',\n",
        "                        )\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') \n",
        "disp_images = []\n",
        "\n",
        "pos_idx = 0\n",
        "neg_idx = 0\n",
        "\n",
        "for image, actual in test_generator:\n",
        "\n",
        "    output = actual\n",
        "\n",
        "    if output == 0 and pos_idx < 3:\n",
        "        pos_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    \n",
        "    if output == 1 and neg_idx <3:\n",
        "        neg_idx += 1\n",
        "        disp_images.append(image[0, ...])\n",
        "\n",
        "    if neg_idx>=3 and pos_idx>=3:\n",
        "        break\n",
        "\n",
        "disp_images = np.array(disp_images)\n",
        "print(disp_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D50d_nkzRfv"
      },
      "source": [
        "import matplotlib as mplot\n",
        "\n",
        "def plot_maps(images, maps, k, dims):\n",
        "    map_size=dims[0]\n",
        "    r_size = dims[1]\n",
        "    r_stride = dims[2]\n",
        "    colors = ['#ff0000', '#ff0080', '#ff00ff', '#8000ff', '#0080ff', '#00ffff', '#00ff80']\n",
        "              \n",
        "    fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
        "    for j , (img, mask) in enumerate(zip(images, maps)):\n",
        "        mask = mask.flatten()\n",
        "        j_a = (j-j%3)//3\n",
        "        j_b = j%3\n",
        "        img = np.asarray(img[:,:,0],dtype=np.float32)\n",
        "        ax[j_a][j_b].imshow(img,cmap=plt.get_cmap('gray'))\n",
        "        \n",
        "        for i in range(k):\n",
        "            a_max = np.argmax(mask)\n",
        "            x_region = a_max%map_size#note, numpy addresses work on arr[y, x, z], compared to image coordinates\n",
        "            y_region = (a_max-(a_max%map_size))//map_size\n",
        "            prob = mask[a_max]\n",
        "       \n",
        "            #if prob<0.5:break\n",
        "            x_pixel = r_stride*(x_region)\n",
        "            y_pixel = r_stride*(y_region)\n",
        "       \n",
        "            #rectangle expects bottom left coordinates. We've generated Top Right\n",
        "            rectangle = mplot.patches.Rectangle((x_pixel, y_pixel), r_size, r_size, edgecolor=colors[i-1],facecolor=\"none\")\n",
        "            ax[j_a][j_b].add_patch(rectangle)\n",
        "            \n",
        "            font = {'color':colors[i-1]}\n",
        "            ax[j_a][j_b].text(x_pixel,y_pixel,s=\"{0:.3f}\".format(prob), fontdict=font)\n",
        "            \n",
        "            mask[a_max]= 0#to help get the next most maximum\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjUmcg4GzRfv"
      },
      "source": [
        "map_model = keras.models.Model(inputs=[model.input], \n",
        "                               outputs=[model.layers[-2].output])\n",
        "\n",
        "final_layer = model.layers[-1]\n",
        "\n",
        "pred_maps = map_model.predict(disp_images)\n",
        "\n",
        "plot_maps(disp_images, pred_maps, 6,  (15, 32, 14 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjITB2XLE4cD"
      },
      "source": [
        "## GC10 METAL SURFACE DATA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVn6OI3yE4ch"
      },
      "source": [
        "### Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ykbQM0E4ch"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trs4b8WXE4ch"
      },
      "source": [
        "filename = 'gc10_metal_defect_dataset.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7AiuIhUE4ci"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'gc10_metal_defect_dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a84YHx-OE4ci"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.2,\n",
        "                            dtype='float32',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cYniU_EE4cj"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "\n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "891W926kG1C6"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "number_of_attributes = len(attribute_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS9n2dA3ljdq"
      },
      "source": [
        "for category in os.listdir(os.path.join(dataset, 'train')):\n",
        "\n",
        "    print(category, \":\", len(os.listdir(os.path.join(dataset, 'train', category))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGgmbyvE4ck"
      },
      "source": [
        "a = next(train_generator)\n",
        "\n",
        "for img, label in zip(a[0][:10], a[1][:10]):\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    print(idx_to_attribute[np.argmax(label, axis=0)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRwaKKND_w_Y"
      },
      "source": [
        "#### Removing some classes with less data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tij9qbyG_0wQ"
      },
      "source": [
        "import shutil\n",
        "\n",
        "cutoff = 100\n",
        "\n",
        "categories = []\n",
        "\n",
        "for category in os.listdir(os.path.join(dataset, 'train')):\n",
        "\n",
        "    length = len(os.listdir(os.path.join(dataset, 'train', category)))\n",
        "\n",
        "    if length < cutoff:\n",
        "\n",
        "        shutil.rmtree(os.path.join(dataset, 'train', category))\n",
        "        shutil.rmtree(os.path.join(dataset, 'test', category))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY-WPhd2F3wL"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "number_of_attributes = len(attribute_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyMuJMYp4_Qt"
      },
      "source": [
        "#### Class weights calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryACbMUt5B20"
      },
      "source": [
        "total = 0\n",
        "lengths = []\n",
        "\n",
        "for category in os.listdir(os.path.join(dataset, 'train')):\n",
        "\n",
        "    length = len(os.listdir(os.path.join(dataset, 'train', category)))\n",
        "    lengths.append(length)\n",
        "    total += length\n",
        "\n",
        "weights = total/ np.array(lengths)\n",
        "weights = weights / 10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN-HWcIe56VL"
      },
      "source": [
        "class_weights = {idx:value for idx, value in enumerate(weights)}\n",
        "print(lengths)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hWUphbGE4cl"
      },
      "source": [
        "#### Generating more data and balancing it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4O8jE5ME4cl"
      },
      "source": [
        "labels = list(train_generator.class_indices.keys())\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcy3qZtkE4cm"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'gc10_metal_defect_dataset')\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            dtype='float32',\n",
        "                        )\n",
        "\n",
        "for folder in ['train_augmented']:\n",
        "\n",
        "    if not os.path.exists(os.path.join(dataset, folder)):\n",
        "        os.mkdir(os.path.join(dataset, folder))\n",
        "\n",
        "save_batch_size = 64\n",
        "\n",
        "for label in labels:\n",
        "\n",
        "    print(label)\n",
        "\n",
        "    for folder in ['train_augmented']:\n",
        "\n",
        "        if not os.path.exists(os.path.join(dataset, folder, label)):\n",
        "            os.mkdir(os.path.join(dataset, folder, label))\n",
        "\n",
        "    train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=save_batch_size,\n",
        "                                                classes=[label],\n",
        "                                                save_to_dir = os.path.join(dataset, 'train_augmented', label),\n",
        "                                                save_prefix='aug',\n",
        "                                                shuffle=True) \n",
        "    \n",
        "    for i in range(10):\n",
        "      \n",
        "        try:\n",
        "            next(train_generator)\n",
        "        except StopIteration:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTJbOVVDKiza"
      },
      "source": [
        "for category in os.listdir(os.path.join(dataset, 'train_augmented')):\n",
        "\n",
        "    print(category, \":\", len(os.listdir(os.path.join(dataset, 'train_augmented', category))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfp85hb5E4cn"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float32',\n",
        "                        )\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train_augmented'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train_augmented'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjcK-9UiE4co"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFcRd6IMFqvg"
      },
      "source": [
        "model = build_model(\"Adam\", 1e-3, number_of_attributes )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIUbn6IXE4co"
      },
      "source": [
        "epochs = 25\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7j3r_TnE4cp"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'gc10_metal_surface_v4(50 eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86k08Xd_E4cq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGgIglSGE4cq"
      },
      "source": [
        "\n",
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V04K25QcE4cq"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'gc10_metal_surface_v4(50 eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VgZSWWE4cr"
      },
      "source": [
        "batch_size = 64\n",
        "                                            \n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test_augmented'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',                                               \n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbB7WzMnE4cr"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQzRONrbE4cr"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "V4 - 50 eps\n",
        "loss : 1.218709111213684\n",
        "accuracy : 0.74964439868927\n",
        "auc : 0.9382346868515015\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_bvE27YE4cs"
      },
      "source": [
        "#### Visualise test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOzLuBERE4cs"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds,axis=0)\n",
        "\n",
        "        confidence = preds[predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgH71bCiE4cs"
      },
      "source": [
        "#### Get Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX9YE92fgmW7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BNhZA7jE4ct"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = keras.layers.Flatten()(classifier_input)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        #last_conv_layer_output = tf.reshape(last_conv_layer_output,[1,-1])\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiYW0V2mE4ct"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-3]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image, verbose=1)[0]\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=0)\n",
        "\n",
        "        confidence = preds[predicted_value] * 100\n",
        "       \n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGZyKHQDL9V5"
      },
      "source": [
        "## STEEL DEFECT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjlCFJs9IHO"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTfRkwT9IHY"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "escF-AtQ9IHZ"
      },
      "source": [
        "def build_model(optimizer, learning_rate, number_of_categories):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    \n",
        "    y_out = keras.layers.Flatten()(mapping_layer)\n",
        "    y_out = keras.layers.Dense(number_of_categories, activation='softmax')(y_out)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpueROgeMAmA"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gef8BJL_73"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "main_dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAdNOTKXfkLI"
      },
      "source": [
        "filename = 'steel_defect_cls_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RzgMKg98iME"
      },
      "source": [
        "dataset = os.path.join(main_dataset_dir, 'steel_defect_cls_products_balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zTKW4PTfkOH"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float32',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZZvuIsLfkQ7"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training') \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEXwHf8VLjLh"
      },
      "source": [
        "attribute_to_idx = train_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)\n",
        "\n",
        "number_of_attributes = len(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqQsCcb4Dgh0"
      },
      "source": [
        "a = next(train_generator)\n",
        "\n",
        "for img in a[0][:5]:\n",
        "\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTXLmvvfkTS"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-3, number_of_attributes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYkxJNzzK4JH"
      },
      "source": [
        "#### Cropping the rectangular images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OhYBVgBBXbm"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset_dir = dataset\n",
        "\n",
        "destination_dir = new_dataset\n",
        "\n",
        "if not os.path.exists(destination_dir):\n",
        "\tos.mkdir(destination_dir)\n",
        "\n",
        "for data_split in os.listdir(dataset_dir):\n",
        "\n",
        "\tprint('\\n', data_split, '\\n')\n",
        "\n",
        "\tdatasplit_path = os.path.join(dataset_dir, data_split)\n",
        "\n",
        "\tdestination_split = os.path.join(destination_dir, data_split)\n",
        "\n",
        "\tif not os.path.exists(destination_split):\n",
        "\t\tos.mkdir(destination_split)\n",
        "\n",
        "\tfor category in os.listdir(datasplit_path):\n",
        "\n",
        "\t\tprint('\\n', category, '\\n')\n",
        "\n",
        "\t\tcategory_path = os.path.join(datasplit_path, category)\n",
        "\n",
        "\t\tdestination_category = os.path.join(destination_split, category)\n",
        "\n",
        "\t\tif not os.path.exists(destination_category):\n",
        "\t\t\tos.mkdir(destination_category)\n",
        "\n",
        "\t\tfor image_name in tqdm(os.listdir(category_path)):\n",
        "\n",
        "\t\t\timage_path = os.path.join(category_path, image_name)\n",
        "\n",
        "\t\t\timage = cv2.imread(image_path)\n",
        "\n",
        "\t\t\theight, width, _ = image.shape\n",
        "\n",
        "\t\t\tnew_width = int(width /6) \n",
        "\n",
        "\t\t\tfor idx in range(6):\n",
        "\n",
        "\t\t\t\tnew_image = image[:, idx* new_width: (idx + 1) * new_width, : ]\n",
        "\n",
        "\t\t\t\tunique_values = len(np.unique(new_image))\n",
        "\n",
        "\t\t\t\tdestination_image_path = os.path.join(destination_category, image_name.split('.')[0] + '_' + str(idx) + '.jpg')\n",
        "\n",
        "\n",
        "\t\t\t\tif unique_values > 120 and not os.path.exists(destination_image_path):\n",
        "\n",
        "\t\t\t\t\tcv2.imwrite(destination_image_path, new_image)\n",
        "\n",
        "\t\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcoJNXKMDAZ"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP8Y1J7QMD8W"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-8, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr],\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jkckAwvhE2h"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roP26cLXhIpX"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'steel_V1(100eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK0goCVbf2d2"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5O-r-VNYDr"
      },
      "source": [
        "for folder in os.listdir(os.path.join(new_dataset, 'train')):\n",
        "    print(folder)\n",
        "    print(len(os.listdir(os.path.join(new_dataset, 'train', folder))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsJl4tALFBv"
      },
      "source": [
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWUqOnJzf4je"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCxzvJVf4m1"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "epochs 100 - V1\n",
        "\n",
        "loss : 0.6304545402526855\n",
        "accuracy : 0.7751004099845886\n",
        "auc : 0.9334365129470825\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_LQyJgTfMnb"
      },
      "source": [
        "#### Visualising the test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkpoi34xf4q6"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlAJVNXfCpxj"
      },
      "source": [
        "#### Visualise Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmV3mfrCsjx"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51FJkm-Cxp3"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APYRgmaJyAF_"
      },
      "source": [
        "## WELDING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjODs0_yyAGB"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvvNjhs4yAGC"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major_Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major_Project/Models/V3'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxZn8mWIyAGC"
      },
      "source": [
        "filename = 'welding_defect_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBNWFamyAGD"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'welding_defect_products_balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NuBydchFByk"
      },
      "source": [
        "for category in os.listdir(dataset + '/train'):\n",
        "    print(category, \":\", len(os.listdir(os.path.join(dataset + '/train', category))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5A3k7jvyAGE"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.75,1.0],\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"constant\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.2,\n",
        "                            dtype='float32',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkM-mFkKyAGE"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n",
        "\n",
        "\"\"\"\n",
        "Found 15799 images belonging to 6 classes.\n",
        "Found 3947 images belonging to 6 classes.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGAnnR_GyAGE"
      },
      "source": [
        "a = next(train_generator)\n",
        "for img in a[0][:10]:\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oF5ZGlhyAGF"
      },
      "source": [
        "number_of_classes = len(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CsT3nkEyAGA"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prYPR-XQyAGA"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxsRmymyAGB"
      },
      "source": [
        "def build_model(optimizer, learning_rate, number_of_attributes):\n",
        "\n",
        "    model = keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=(224,224,3), include_top=False, pooling = 'average')\n",
        "    model.trainable = False\n",
        "\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(16, (3,3))(model.output)\n",
        "    mapping_layer = keras.layers.Conv2DTranspose(1, (3,3))(mapping_layer)\n",
        "    mapping_layer = keras.layers.Activation(\"sigmoid\")(mapping_layer)\n",
        "\n",
        "    y_out = keras.layers.Flatten()(mapping_layer)\n",
        "    y_out = keras.layers.Dense(32, activation='relu')(y_out)\n",
        "    y_out = keras.layers.Dense(number_of_attributes, activation='softmax')(y_out)\n",
        "\n",
        "    final_model = keras.models.Model(inputs=[model.input],\n",
        "                                     outputs=[y_out])\n",
        "\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True )\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    final_model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return final_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpd2rG1Sdyry"
      },
      "source": [
        "model = build_model(\"SGD\", 1e-3, number_of_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LffvkuKjyAGG"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNza8m0MyAGG"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-8, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr],\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcxQKLl-yAGG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtTL8KAEyAGH"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'welding_V1(10eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzODX_xmyAGH"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nftkn39dig7U"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'welding_V1(10eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO1P2WzwyAGI"
      },
      "source": [
        "for folder in os.listdir(os.path.join(new_dataset, 'train')):\n",
        "    print(folder)\n",
        "    print(len(os.listdir(os.path.join(new_dataset, 'train', folder))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-twiW9O1yAGI"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcWcm4NyAGJ"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrB6PI97yAGJ"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "epochs 10\n",
        "\n",
        "loss : 0.316101998090744\n",
        "accuracy : 0.9012289643287659\n",
        "auc : 0.9875184297561646\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEwJaRRUyAGJ"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35FEFe_JyAGK"
      },
      "source": [
        "#### Visualise Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBOZZ3RXyAGK"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = model.layers[-2](x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI2p3tmsyAGL"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgzqleo5jyWI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}