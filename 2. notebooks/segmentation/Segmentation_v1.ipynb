{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RYv62k-uGQUV",
        "JDYvlKbxKxWq",
        "wqneUq65LCM0",
        "d1P0NR7LLT6y",
        "a7VSrlLk2VdJ",
        "mVSR032UdCvf",
        "_ymgD7vLrA-E",
        "LSoM7XTQL5yS",
        "xskYOOLoL7ol",
        "gjgkntmwdupb",
        "EkZwCBP48ncU",
        "g566NyGo1_re",
        "nGZyKHQDL9V5",
        "BAjlCFJs9IHO",
        "DpueROgeMAmA",
        "wCcoJNXKMDAZ",
        "iK0goCVbf2d2",
        "_ZzyozMIjPTQ",
        "frdg4R1BjPTf",
        "YSWVQhQHjQxW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBslyrAnjBht"
      },
      "source": [
        "!nvidia-smi "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZytusM1GPCJ"
      },
      "source": [
        "# Segmentation model - Version 1\n",
        "\n",
        "The classification backbone of the model is VGG-16 network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvpGmGJE3Nj_"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ5iCdZVKsaN"
      },
      "source": [
        "## CASTING DATA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYv62k-uGQUV"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2E_4VPv4afX"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.GlobalMaxPooling2D()(x_map)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    if out_type == \"classify\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=y)\n",
        "    if out_type == \"map\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDbFkajCHDgG"
      },
      "source": [
        "map_model = build_model(\"Adam\", 1e-3, \"map\")\n",
        "model = build_model(\"Adam\", 1e-3, \"classify\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYvlKbxKxWq"
      },
      "source": [
        "### Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZIlPBW4KwpV"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NAO88PU8--1"
      },
      "source": [
        "filename = 'casting_dataset.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpDXSDujh2Ql"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'casting_dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpd2cxHmU0VY"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            brightness_range = [0.5,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=1.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivTMPvTVdpJo"
      },
      "source": [
        "print(len(os.listdir(os.path.join(dataset, 'train', 'def_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'train', 'ok_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'test', 'def_front'))))\n",
        "print(len(os.listdir(os.path.join(dataset, 'test', 'ok_front'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mkka89-hLb7"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqneUq65LCM0"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okBDv1VnLDmm"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0l1fuKUn4Ld"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'casting_V3(100 eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxAVY77vFM4-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1P0NR7LLT6y"
      },
      "source": [
        "\n",
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ma34YeHq91"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'casting_V2.h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gro2RJZouEs6"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6kFM1rTpkBB"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dV7_zvvzm3v"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "50 eps\n",
        "\n",
        "loss : 0.11778640002012253\n",
        "accuracy : 0.96321scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "print(scores)52318954468\n",
        "auc : 0.9908440709114075\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "100 eps\n",
        "\n",
        "loss : 0.04719378054141998\n",
        "accuracy : 0.9863760471343994\n",
        "auc : 0.9984898567199707\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VSrlLk2VdJ"
      },
      "source": [
        "#### Visualise test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DELw_VzGLWW3"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = (preds > 0.75).astype(np.int)\n",
        "\n",
        "        if predicted_value == 0:\n",
        "\n",
        "            confidence = (1- preds) * 100\n",
        "        else:\n",
        "            confidence = preds * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVSR032UdCvf"
      },
      "source": [
        "#### Get Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfVxtpRzdHtJ"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlFTBWR0DHJ"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-3]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image, verbose=1)[0][0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "\n",
        "        predicted_value = (preds > 0.6).astype(np.int)\n",
        "\n",
        "        if predicted_value == 0:\n",
        "\n",
        "            confidence = (1- preds) * 100\n",
        "        else:\n",
        "            confidence = preds * 100\n",
        "\n",
        "       \n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbxmdITkL2TX"
      },
      "source": [
        "## SOLAR PANEL DATA \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ymgD7vLrA-E"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITSyZfqqrF3x"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh8gvjlsrA-E"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type, categories):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.Flatten()(x_map)\n",
        "    y_out = keras.layers.Dense(categories, activation='softmax')(y)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    if out_type == \"classify\":casting_V2\n",
        "        model = keras.models.Model(inputs=input_img, outputs=y_out)\n",
        "    if out_type == \"map\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kb5eWjurA-E"
      },
      "source": [
        "map_model = build_model(\"Adam\", 1e-3, \"map\", 2)\n",
        "model = build_model(\"Adam\", 1e-3, \"classify\", 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSoM7XTQL5yS"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIHmBY-nL5Kb"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtcvlhoacpY7"
      },
      "source": [
        "filename = 'solar_panels_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihWOG3lSdHTA"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'solar_panels_products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjUfrM9dOGv"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.5,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.75,\n",
        "                            dtype='float64',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnWkTdw8dR1v"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training',\n",
        "                                                shuffle=True) \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xskYOOLoL7ol"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQGcviwL8pP"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, min_lr = 1e-7, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j7ujMhXdZLC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ux2OtQtdZN1"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'solar_v1(50eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgkntmwdupb"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vX7bxxu1e8N"
      },
      "source": [
        "model = keras.models.load_model(os.path.join(model_dir, 'solar_v1(50eps).h5'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdCpMoV4wwLP"
      },
      "source": [
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTYizERedt3-"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6X2E74dz26"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "50 epochs\n",
        "\n",
        "loss : 0.38369879126548767\n",
        "accuracy : 0.9211195707321167\n",
        "auc : 0.9531559944152832\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkZwCBP48ncU"
      },
      "source": [
        "#### Visualise test data results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sc-OlBKdz54"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g566NyGo1_re"
      },
      "source": [
        "#### Get Activation Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q7ojLfB2CMv"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FR_-FDE2Ipe"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGZyKHQDL9V5"
      },
      "source": [
        "## STEEL DEFECT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjlCFJs9IHO"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTfRkwT9IHY"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "escF-AtQ9IHZ"
      },
      "source": [
        "def build_model(optimizer, learning_rate, out_type, categories):\n",
        "\n",
        "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')#sets values to be float16 for nvidia 2000,3000 series GPUs, plus others im sure\n",
        "    \n",
        "    input_img = keras.layers.Input(shape=(224, 224, 3))\n",
        "  \n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(input_img)\n",
        "    x = keras.layers.Conv2D(8, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(16, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(16, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(32, 2,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(32, 3,padding='valid',activation='selu', kernel_initializer='lecun_normal',dtype=policy)(x)\n",
        "    x = keras.layers.MaxPooling2D(2)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)    \n",
        "\n",
        "    x = keras.layers.Conv2D(16, 1, activation=\"selu\",kernel_initializer=\"lecun_normal\",dtype=policy)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='linear')(x)\n",
        "    x_map = keras.activations.sigmoid(x)\n",
        "\n",
        "    y = keras.layers.Flatten()(x_map)\n",
        "    y_out = keras.layers.Dense(categories, activation='softmax')(y)\n",
        "    \n",
        "    if optimizer == \"SGD\":\n",
        "        #looks like pretty good but noisy results with no momentum, lets check 0.9...\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    if optimizer == \"RMSprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    if optimizer == \"Adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    if out_type == \"classify\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=y_out)\n",
        "    if out_type == \"map\":\n",
        "        model = keras.models.Model(inputs=input_img, outputs=x_map)\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy','AUC'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpueROgeMAmA"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gef8BJL_73"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAdNOTKXfkLI"
      },
      "source": [
        "filename = 'steel_defect_cls_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RzgMKg98iME"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'steel_defect_cls_products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zTKW4PTfkOH"
      },
      "source": [
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.25,\n",
        "                            height_shift_range=0.25,\n",
        "                            brightness_range = [0.6,1.0],\n",
        "                            zoom_range=0.2,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.2,\n",
        "                            dtype='float64',\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZZvuIsLfkQ7"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='training') \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                subset='validation') \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmjzmPvC9QFq"
      },
      "source": [
        "number_of_classes = len(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTXLmvvfkTS"
      },
      "source": [
        "map_model = build_model(\"SGD\", 1e-3, \"map\", number_of_classes)\n",
        "model = build_model(\"SGD\", 1e-3, \"classify\", number_of_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcoJNXKMDAZ"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP8Y1J7QMD8W"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, min_lr = 1e-8, factor=0.5, verbose=1)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr],\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jkckAwvhE2h"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"AUC\")\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Learning rate')\n",
        "plt.plot(history.history['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roP26cLXhIpX"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'steel_V1(50eps).h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK0goCVbf2d2"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5O-r-VNYDr"
      },
      "source": [
        "for folder in os.listdir(os.path.join(dataset, 'train')):\n",
        "    print(folder)\n",
        "    print(len(os.listdir(os.path.join(dataset, 'train', folder))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsJl4tALFBv"
      },
      "source": [
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWUqOnJzf4je"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMCxzvJVf4m1"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "scores_keys = ['loss', 'accuracy', 'auc']\n",
        "\n",
        "for key,score in zip(scores_keys, scores):\n",
        "\n",
        "    print(key, ':', score)\n",
        "\n",
        "\"\"\"\n",
        "epochs 50\n",
        "\n",
        "loss : 0.8872455358505249\n",
        "accuracy : 0.7154929637908936\n",
        "auc : 0.8439496159553528\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkpoi34xf4q6"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        preds = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlAJVNXfCpxj"
      },
      "source": [
        "#### Visualise Activation maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmV3mfrCsjx"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer, classifier_layer\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    \n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = classifier_layer(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51FJkm-Cxp3"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "last_conv_layer = model.layers[-4]\n",
        "classifier_layer = model.layers[-1]\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] * 255\n",
        "\n",
        "        image = np.expand_dims(images[i], axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "\n",
        "        actual_value = np.argmax(output[i], axis=0)\n",
        "\n",
        "        predicted_value = np.argmax(preds, axis=1)[0]\n",
        "\n",
        "        confidence = preds[0][predicted_value] * 100\n",
        "\n",
        "        # Generate class activation heatmap\n",
        "        heatmap = make_gradcam_heatmap(\n",
        "            image, model, last_conv_layer, classifier_layer\n",
        "        )\n",
        "\n",
        "\n",
        "        # We rescale heatmap to a range 0-255\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "        # We use jet colormap to colorize heatmap\n",
        "        jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "        # We use RGB values of the colormap\n",
        "        jet_colors = jet(np.arange(256))[:, :3]\n",
        "        jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "        # We create an image with RGB colorized heatmap\n",
        "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "        # Superimpose the heatmap on original image\n",
        "        superimposed_img = jet_heatmap * 0.6 + img\n",
        "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Confidence\", confidence, \"%\")\n",
        "        print(\"Actual_value\", idx_to_attribute[int(actual_value)])\n",
        "        print(\"Predicted value\", idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "        \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZzyozMIjPTQ"
      },
      "source": [
        "## SURFACE DEFECT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOJrXts9jPTZ"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8-D77KfjPTb"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HACAXNOdjPTc"
      },
      "source": [
        "filename = 'solar_panels_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTBGqZrljPTd"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'casting_dataset')\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            \n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.5,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKfOCpqYjPTd"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training') \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation') \n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frdg4R1BjPTf"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbNChot7jPTf"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glT4iZdAjPTf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tblv6fo0jPTg"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'casting.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brNW_0K5jPTg"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJbLcLzjPTg"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4uqP_7tjPTh"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxC0pqLBjPTh"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        confidence = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "        \n",
        "        predicted_value = (confidence > 0.5).astype(np.int)\n",
        "\n",
        "        print(\"Confidence\", confidence)\n",
        "        print(idx_to_attribute[int(actual_value)])\n",
        "        print(idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWVQhQHjQxW"
      },
      "source": [
        "## WELDING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tdx4b5ljQxX"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg06VjpxjQxX"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Major Project/Datasets/datasets'\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/Major Project/Models/V1'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQWpTlN-jQxY"
      },
      "source": [
        "filename = 'solar_panels_products.tar.xz'\n",
        "tar_file = os.path.join(dataset_dir, filename)\n",
        "\n",
        "my_tar = tarfile.open(tar_file)\n",
        "my_tar.extractall(dataset_dir) # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSJgacOjQxY"
      },
      "source": [
        "dataset = os.path.join(dataset_dir, 'casting_dataset')\n",
        "\n",
        "generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "                            \n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range = [0.5,1.0],\n",
        "                            zoom_range=0.1,\n",
        "                            rescale=1./255,\n",
        "                            fill_mode=\"nearest\",\n",
        "                            cval=0.0,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            validation_split=0.1,\n",
        "                            dtype='float64',\n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n29n0HZzjQxZ"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='training') \n",
        "                                            \n",
        "val_generator = generator.flow_from_directory( os.path.join(dataset, 'train'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                subset='validation') \n",
        "\n",
        "test_generator = generator.flow_from_directory( os.path.join(dataset, 'test'), \n",
        "                                                target_size=(224, 224), \n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXJotie0jQxa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TC_aUG4jQxa"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sxMg2JjQxa"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs= epochs,\n",
        "                    validation_data = val_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdkyunF1jQxb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HyUE136jQxb"
      },
      "source": [
        "model.save(os.path.join(model_dir, 'casting.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv_VZykljQxc"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3KQLRpmjQxc"
      },
      "source": [
        "attribute_to_idx = test_generator.class_indices\n",
        "idx_to_attribute = {value:key for key,value in attribute_to_idx.items()}\n",
        "\n",
        "print(attribute_to_idx)\n",
        "print(idx_to_attribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AScEbsUJjQxc"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, verbose=1)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CMQAlUfjQxc"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for idx, (images, output) in enumerate(test_generator):\n",
        "\n",
        "    if idx == 1:\n",
        "        break\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        cv2_imshow(image * 255)\n",
        "\n",
        "        confidence = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "        actual_value = output[i]\n",
        "        \n",
        "        predicted_value = (confidence > 0.5).astype(np.int)\n",
        "\n",
        "        print(\"Confidence\", confidence)\n",
        "        print(idx_to_attribute[int(actual_value)])\n",
        "        print(idx_to_attribute[int(predicted_value)])\n",
        "    \n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}