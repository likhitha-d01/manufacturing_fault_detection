{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ZtYWi6C5m_"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TObSbU1DDWcY"
      },
      "source": [
        "# Casting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By6BKEW-3Lgj"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrzjiKcy7fzA"
      },
      "source": [
        "main_dir = '/content/drive/MyDrive/Major Project/casting_dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDdEW6rp7r7W"
      },
      "source": [
        "train_dir = os.path.join(main_dir, 'train')\n",
        "\n",
        "categories = ['def_front', 'ok_front']\n",
        "\n",
        "X_data = []\n",
        "Y_data = []\n",
        "\n",
        "count = 0\n",
        "for idx, category in enumerate(categories):\n",
        "    \n",
        "    images_dir = os.path.join(train_dir, category)\n",
        "\n",
        "    for image in os.listdir(images_dir):\n",
        "\n",
        "        image_path = os.path.join(images_dir, image)\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        \n",
        "        image = image/ 255.0\n",
        "\n",
        "        X_data.append(image)\n",
        "        \n",
        "        count +=1\n",
        "        print(count)\n",
        "    \n",
        "    Y_data += [idx] * len(X_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFcIuncb8s-y"
      },
      "source": [
        "X_data = np.array(X_data)\n",
        "Y_data = np.array(Y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04pvi74z82nS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(X_data, Y_data, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aADF2bb79dlJ"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "model = ResNet50(include_top=True,\n",
        "                 weights=None,\n",
        "                 input_shape = (300,300,3), \n",
        "                 classes=2)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giOCegL_-G6T"
      },
      "source": [
        "history = model.fit(train_x, train_y,\n",
        "                    batch_size = 32,\n",
        "                    validation_data = (val_x, val_y),\n",
        "                    validation_steps = 32,\n",
        "                    epochs = 50,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr = 1e-8)]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0tHTKae_GpJ"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYJFwlAx_Pg1"
      },
      "source": [
        "test_dir = os.path.join(main_dir, 'test')\n",
        "\n",
        "defective_imgs = [os.path.join(test_dir,'def_front',i) for i in os.listdir( os.path.join( test_dir, 'def_front') )]\n",
        "non_defective_imgs = [os.path.join(test_dir,'ok_front',i) for i in os.listdir( os.path.join( test_dir, 'ok_front') )]\n",
        "\n",
        "test_images = defective_imgs + non_defective_imgs\n",
        "\n",
        "random.shuffle(test_images)\n",
        "number_of_tests = 10\n",
        "\n",
        "idx_to_category = {0:'def_front', 1:'ok_front'}\n",
        "\n",
        "for idx in range(number_of_tests):\n",
        "    test_image = cv2.imread(os.path.join(test_dir, test_images[idx]))\n",
        "    cv2_imshow(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    result = model.predict(test_image, verbose=1)\n",
        "    print(result)\n",
        "    result = np.argmax(result[0])\n",
        "    print(idx_to_category[int(result)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lid8Jg30D0YL"
      },
      "source": [
        "# get test accuracy\n",
        "# save model with documentation\n",
        "# upload other datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz1iV64M1CcL"
      },
      "source": [
        "train_dir = os.path.join(main_dir, 'train')\n",
        "\n",
        "categories = ['def_front', 'ok_front']\n",
        "\n",
        "all_files = [os.path.join(category, image) for category in categories for image in os.listdir(os.path.join(train_dir, category))]\n",
        "\n",
        "random.shuffle(all_files)\n",
        "\n",
        "split_ratio = 0.1\n",
        "\n",
        "train_files = all_files[ int(split_ratio * len(all_files)) : ]\n",
        "\n",
        "val_files = all_files[ : int(split_ratio * len(all_files)) ]\n",
        "\n",
        "def dataloader(train_dir, files, batch_size=32):\n",
        "\n",
        "    while True:\n",
        "\n",
        "        n=0\n",
        "\n",
        "        X_data = []\n",
        "        Y_data = []\n",
        "\n",
        "        for img in files:\n",
        "\n",
        "            image_path = os.path.join(train_dir, img)\n",
        "            image = cv2.imread(image_path)\n",
        "                \n",
        "            image = image/ 255.0\n",
        "\n",
        "            X_data.append(image)\n",
        "            \n",
        "            if 'def_front' in img:\n",
        "                #Y_data.append(0.0)\n",
        "\n",
        "                Y_data.append( keras.utils.to_categorical([0], num_classes=2)[0] )\n",
        "\n",
        "            \n",
        "            if 'ok_front' in img:\n",
        "                #Y_data.append(1.0)\n",
        "            \n",
        "                Y_data.append( keras.utils.to_categorical([1], num_classes=2)[0] )\n",
        "            n += 1\n",
        "\n",
        "            if n == batch_size:\n",
        "\n",
        "                \n",
        "                yield ( np.array(X_data, dtype='float64') , np.array(Y_data, dtype='float64'))\n",
        "            \n",
        "                n = 0\n",
        "\n",
        "                X_data, Y_data = [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPu3uGKZ3Ycw"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = dataloader(train_dir, train_files, batch_size = batch_size)\n",
        "val_dataloader = dataloader(train_dir, val_files, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICgXbNEz3jlf"
      },
      "source": [
        "data = next(train_dataloader)\n",
        "print(data[0].shape)\n",
        "print(data[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nutHJ-3M5Wxd"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "model = ResNet50(include_top=True,\n",
        "                 weights=None,\n",
        "                 input_shape = (300,300,3), \n",
        "                 classes=2)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R11YBSZ56i3"
      },
      "source": [
        "history = model.fit_generator(train_dataloader,\n",
        "                    validation_data = val_dataloader,\n",
        "                    steps_per_epoch = len(train_files) // batch_size,\n",
        "                    validation_steps = len(val_files)// batch_size,\n",
        "                    epochs = 50,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr = 1e-8)]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9By-hAPnBfqx"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JRW1YPzDZsM"
      },
      "source": [
        "# Solar Panels Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe96TVcXDfo0"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTGTxZ45Diiy"
      },
      "source": [
        "# Steel Defect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFDH13xCDkpO"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftJAZY-kDpZM"
      },
      "source": [
        "# Surface Defect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHWhiGBDsT2"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMlx4PTCDtUs"
      },
      "source": [
        "# Welding Defect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G3vkMtUDvMz"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}